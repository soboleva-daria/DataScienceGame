{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  datetime import datetime\n",
    "import time\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time_of_day(x): \n",
    "    #утро день вечер ночь, можно как то по другому пороги выставить, не разбирался\n",
    "    t = x.hour\n",
    "    if  0<= t <= 6:\n",
    "        return 0\n",
    "    elif 7<=t<=12:\n",
    "        return 1\n",
    "    elif 13<=t<=19:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numdate2date(x):\n",
    "    # для того чтобы перевести release_date в таймстамп и посчитать любит ли юзер слушать новые или старые треки\n",
    "    try:\n",
    "        return time.mktime(datetime.strptime(str(x), '%Y%m%d').timetuple())\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature2cat(x):\n",
    "    # самые \"умные\" пороги для преобразования фичей в категориальные \n",
    "    cats = x.describe()\n",
    "    cat_1 = cats['25%']\n",
    "    cat_2 = cats['50%']\n",
    "    cat_3 = cats['75%']\n",
    "    \n",
    "    cat_x = np.copy(x)\n",
    "    cat_x[x<cat_1] = 0\n",
    "    cat_x[(x>=cat_1)&(x<cat_2)] = 1\n",
    "    cat_x[(x>=cat_2)&(x<cat_3)] = 2\n",
    "    cat_x[x>=cat_3] = 3\n",
    "    return cat_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_statistics(statistic_set, train, features, target):\n",
    "    # основная функция, которая считает статистики\n",
    "    # statistic_set -- датафрейм по которому нужно считать их\n",
    "    # train -- куда мерджить результаты\n",
    "    # features -- итератор из списков/кортежей фичей, по которым групбаить\n",
    "    # target -- ну собственно колонка по которой считать статистики\n",
    "    train = train.copy()\n",
    "    for f in features:\n",
    "        f_ = list(f)\n",
    "        \n",
    "        counts = statistic_set.groupby(f_).size().reset_index()\n",
    "        c = '&'.join(f_)+'-'+target+'_size'\n",
    "        counts.columns = f_+ [c]\n",
    "        train = pd.merge(train, counts, on=f_, how='left')\n",
    "        \n",
    "        counts = statistic_set.groupby(f_)[target].mean().reset_index()\n",
    "        c = '&'.join(f_)+'-'+target+'_mean'\n",
    "        counts.columns = f_+ [c]\n",
    "        train = pd.merge(train, counts, on=f_, how='left')\n",
    "        \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train.sort_values(by='ts_listen', inplace=True) # для того чтобы удалять БУДУЩЕЕ при генерации выборок\n",
    "test.sort_values(by='ts_listen', inplace=True)\n",
    "\n",
    "artist_info = pd.read_csv('./api_data/artist_info.csv') \n",
    "album_info = pd.read_csv('./api_data/albums_info.csv')\n",
    "tracks_info = pd.read_csv('./api_data/songs_info.csv')\n",
    "tracks_info= tracks_info[['media_id', 'disk_number', 'bpm', 'explicit_lyrics', 'gain', 'track_position', 'rank']]\n",
    "\n",
    "train = pd.merge(train, artist_info, on='artist_id', how='left')\n",
    "train = pd.merge(train, album_info, on='album_id', how='left')\n",
    "train = pd.merge(train, tracks_info, on='media_id', how='left')\n",
    "\n",
    "test = pd.merge(test, artist_info, on='artist_id', how='left')\n",
    "test = pd.merge(test, album_info, on='album_id', how='left')\n",
    "test = pd.merge(test, tracks_info, on='media_id', how='left')\n",
    "\n",
    "\n",
    "del artist_info\n",
    "del album_info\n",
    "del tracks_info\n",
    "train['time_of_day']=train.ts_listen.apply(datetime.utcfromtimestamp).apply(get_time_of_day)\n",
    "test['time_of_day']=test.ts_listen.apply(datetime.utcfromtimestamp).apply(get_time_of_day)\n",
    "test['diff_date'] = test.ts_listen - test.release_date.apply(numdate2date)\n",
    "train['diff_date'] = train.ts_listen - train.release_date.apply(numdate2date)\n",
    "train_test = pd.concat([train, test])\n",
    "train_test.fillna(0, inplace=True)\n",
    "\n",
    "train_test['user_age_cat'] = feature2cat(train_test.user_age)\n",
    "train_test['diff_date_cat'] = feature2cat(train_test.diff_date)\n",
    "train_test['media_duration_cat'] = feature2cat(train_test.media_duration)\n",
    "train_test['nb_fan_cat'] = feature2cat(train_test.nb_fan)\n",
    "train_test['nb_album_cat'] = feature2cat(train_test.nb_album)\n",
    "train_test['nb_tracks_cat'] = feature2cat(train_test.nb_tracks)\n",
    "train_test['fans_cat'] = feature2cat(train_test.fans)\n",
    "train_test['bpm_cat'] = feature2cat(train_test.bpm)\n",
    "train_test['track_position_cat'] = feature2cat(train_test.track_position)\n",
    "train_test['rank_cat'] = feature2cat(train_test['rank'])\n",
    "train_test['gain_cat'] = feature2cat(train_test['gain'])\n",
    "\n",
    "train_test.explicit_lyrics = train_test.explicit_lyrics.astype(int)\n",
    "train_test.radio = train_test.radio.fillna(0).astype(int)\n",
    "\n",
    "train = train_test.iloc[:train.shape[0]].copy()\n",
    "test = train_test.iloc[train.shape[0]:].copy()\n",
    "del train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "объявим фичи по которым будем считать статистики\n",
    "ну и собственно их же комбинации (для больших степеней нужно подсократить список конечна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['user_id', 'media_id','album_genre_id', 'album_id', 'artist_id', 'context_type', 'genre_id', 'listen_type'\n",
    "               , 'platform_family', 'platform_name', 'time_of_day', 'user_gender', 'user_age_cat', 'diff_date_cat', \n",
    "                'media_duration_cat', 'nb_fan_cat', 'nb_album_cat', 'nb_tracks_cat', 'radio'\n",
    "                , 'bpm_cat', 'track_position_cat', 'rank_cat', 'gain_cat', 'explicit_lyrics'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посчитаем все для тестовой выборки сначала, так как потом ТРЕЙН ПОРТИТСЯ, а заново считать долга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make test\n",
    "test = count_statistics(train, test, combinations(cat_features , 1), 'is_listened')\n",
    "test = count_statistics(train, test, combinations(cat_features , 2), 'is_listened')\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0 15971\n",
      "0\n",
      "1\n",
      "1 30779\n"
     ]
    }
   ],
   "source": [
    "validation = []\n",
    "num_tracks = 6 # на сколько треков назад делать датасет, хорошо бы настроить тоже\n",
    "for i in range(num_tracks):\n",
    "    v = train[train.listen_type==1].groupby(['user_id']).last().reset_index() # GET LAST TRACK\n",
    "    \n",
    "    \n",
    "    tmp = v[['user_id', 'ts_listen']].copy()\n",
    "    tmp.columns = ['user_id', 'max_time']\n",
    "    \n",
    "    \n",
    "    train = pd.merge(train, tmp, on='user_id', how='left')\n",
    "    train = train[train.ts_listen < train.max_time] #DELETE \"FUTURE\"\n",
    "    train.drop('max_time',axis=1, inplace=True)\n",
    "    \n",
    "    # make features\n",
    "    c = train.columns.difference(['is_listened', 'listen_type', 'ts_listen'])\n",
    "    print('0')\n",
    "    v_new = count_statistics(train, v, combinations(cat_features , 1), 'is_listened')\n",
    "    print('1')\n",
    "    v_new = count_statistics(train, v_new, combinations(cat_features , 2), 'is_listened')\n",
    "\n",
    "    v_new['track_num'] = i\n",
    "    if i == 0:\n",
    "        validation = v_new.copy()\n",
    "    else:\n",
    "        validation = pd.concat([validation, v_new])\n",
    "    print(i, validation.shape[0])\n",
    "    \n",
    "validation.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1 = validation[(validation.track_num>0)].copy()\n",
    "X_test_1  = validation[validation.track_num==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = validation.columns.difference(['name','track_num', 'is_listened', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.721243202132\n"
     ]
    }
   ],
   "source": [
    "clf1 = xgb.XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.1)\n",
    "clf1.fit(X_train_1[c], X_train_1['is_listened'])\n",
    "score_1 = roc_auc_score(X_test_1['is_listened'], clf1.predict_proba(X_test_1[c])[:, 1])\n",
    "print(score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = validation[validation.track_num<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(validation[c], validation['is_listened'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['is_listened'] = clf.predict_proba(test[c])[:, 1]\n",
    "ans = test[['sample_id', 'is_listened']].copy()\n",
    "ans.sort_values(by='sample_id', inplace=True)\n",
    "ans['sample_id'] = ans.sample_id.astype(int)\n",
    "ans.to_csv('ans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0</td>\n",
       "      <td>0.974809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>1</td>\n",
       "      <td>0.752584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>2</td>\n",
       "      <td>0.761466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>3</td>\n",
       "      <td>0.688747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15626</th>\n",
       "      <td>4</td>\n",
       "      <td>0.902059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id  is_listened\n",
       "774            0     0.974809\n",
       "7507           1     0.752584\n",
       "8695           2     0.761466\n",
       "2948           3     0.688747\n",
       "15626          4     0.902059"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
